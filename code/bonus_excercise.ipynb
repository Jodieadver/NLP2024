{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise mutual information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the words from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the brown corpus:  988331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 62713, 'of': 36080, 'and': 27915, 'to': 25732, 'a': 21881, 'in': 19536, 'that': 10237, 'is': 10011, 'was': 9777, 'for': 8841, ...})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "words = brown.words()\n",
    "\n",
    "# remove punctuation\n",
    "words = [word for word in words if word.isalnum()]\n",
    "\n",
    "# print number of words\n",
    "print(\"Number of words in the brown corpus: \", len(words))\n",
    "\n",
    "# get the frequency distribution of the words\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "# get words that occur ten or more times\n",
    "high_freq_words = [word for word in words if fdist[word] >= 10]\n",
    "\n",
    "\n",
    "fdist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "bigrams = list(nltk.bigrams(words))\n",
    "\n",
    "# get frequency distribution of the bigrams\n",
    "bigrams_fdist = nltk.FreqDist(bigrams)\n",
    "\n",
    "# calculate the pmi for all the bigrams\n",
    "pmi = {}\n",
    "for bigram in bigrams:\n",
    "    w1, w2 = bigram\n",
    "\n",
    "    # calculate the pmi with the formula\n",
    "\n",
    "    if fdist[w1] >= 10 and fdist[w2] >= 10:\n",
    "\n",
    "        # bigram probability\n",
    "        bigram_prob = bigrams_fdist[bigram] / len(bigrams)\n",
    "\n",
    "        # unigram probabilities\n",
    "        w1_prob = fdist[w1] / len(words)\n",
    "        w2_prob = fdist[w2] / len(words)\n",
    "\n",
    "        pmi[bigram] = math.log2(bigram_prob / (w1_prob * w2_prob))\n",
    "\n",
    "        if pmi[bigram] > 40:\n",
    "            print(\"we have a big pmi: \", bigram, pmi[bigram])\n",
    "            print(\"bigram prob: \", bigram_prob)\n",
    "            print(\"w1 prob: \", w1_prob)\n",
    "            print(\"w2 prob: \", w2_prob)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the pairs with highest and lowest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 word pairs with the highest pmi value: \n",
      "(('Hong', 'Kong'), 16.45520460843694)\n",
      "(('Viet', 'Nam'), 15.914636227074237)\n",
      "(('Pathet', 'Lao'), 15.827173385823897)\n",
      "(('Simms', 'Purdew'), 15.827173385823897)\n",
      "(('7th', 'Cavalry'), 15.815100553523322)\n",
      "(('El', 'Paso'), 15.592708132186875)\n",
      "(('Herald', 'Tribune'), 15.562119812353451)\n",
      "(('Lo', 'Shu'), 15.522318804295477)\n",
      "(('Islands', 'Guam'), 15.48167681979813)\n",
      "(('WTV', 'antigen'), 15.436588930269593)\n",
      "(('Gray', 'Eyes'), 15.400063054244479)\n",
      "(('Puerto', 'Rico'), 15.32967372635308)\n",
      "(('Internal', 'Revenue'), 15.32967372635308)\n",
      "(('decomposition', 'theorem'), 15.107281305016633)\n",
      "(('Saxon', 'Shore'), 15.081746212909495)\n",
      "(('anionic', 'binding'), 15.078134959357117)\n",
      "(('carbon', 'tetrachloride'), 15.02927879301536)\n",
      "(('Common', 'Market'), 15.007745631465719)\n",
      "(('unwed', 'mothers'), 15.007745631465719)\n",
      "(('Beverly', 'Hills'), 14.991804087596698)\n",
      "\n",
      "20 word pairs with the lowest pmi value: \n",
      "(('a', 'the'), -10.439231740746157)\n",
      "(('the', 'it'), -8.73673012210247)\n",
      "(('the', 'a'), -8.439231740746157)\n",
      "(('I', 'the'), -8.355275603154972)\n",
      "(('the', 'not'), -8.132650214769575)\n",
      "(('with', 'of'), -7.999885771828044)\n",
      "(('to', 'was'), -7.991815883732122)\n",
      "(('the', 'this'), -7.975309650099769)\n",
      "(('he', 'of'), -7.905074525641487)\n",
      "(('the', 'the'), -7.87085476156574)\n",
      "(('on', 'of'), -7.867004134837505)\n",
      "(('an', 'the'), -7.812189184622835)\n",
      "(('a', 'is'), -7.7920532977044745)\n",
      "(('the', 'his'), -7.680498479997007)\n",
      "(('the', 'but'), -7.575949840444924)\n",
      "(('He', 'the'), -7.563905230154363)\n",
      "(('of', 'of'), -7.555832287153645)\n",
      "(('in', 'of'), -7.478122976055909)\n",
      "(('the', 'they'), -7.4590725889103995)\n",
      "(('the', 'would'), -7.408242111511699)\n"
     ]
    }
   ],
   "source": [
    "sorted_pmi = sorted(pmi.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"20 word pairs with the highest pmi value: \")\n",
    "for i in range(20):\n",
    "    print(sorted_pmi[i])\n",
    "\n",
    "print(\"\\n20 word pairs with the lowest pmi value: \")\n",
    "for i in range(1, 21):\n",
    "    print(sorted_pmi[-i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
